{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/HARSHA/Downloads/forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#df['size_category'].value_counts().plot.pie()\n",
    "#plt.show()\n",
    "#print(df['size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.pairplot(df,hue='size_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "x=x.apply(LabelEncoder().fit_transform)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = y.apply(LabelEncoder().fit_transform)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 40s 49ms/step - loss: 0.6636 - accuracy: 0.8687 - val_loss: 0.5530 - val_accuracy: 0.6959\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8224 - val_loss: 0.2947 - val_accuracy: 0.8596\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9574 - val_loss: 0.1671 - val_accuracy: 0.9240\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9750 - val_loss: 0.1344 - val_accuracy: 0.9415\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9612 - val_loss: 0.1290 - val_accuracy: 0.9415\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.1322 - val_accuracy: 0.9532\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9758 - val_loss: 0.1222 - val_accuracy: 0.9474\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9624 - val_loss: 0.1387 - val_accuracy: 0.9415\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.1173 - val_accuracy: 0.9474\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9933 - val_loss: 0.1367 - val_accuracy: 0.9532\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9767 - val_loss: 0.1248 - val_accuracy: 0.9532\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.1235 - val_accuracy: 0.9532\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9851 - val_loss: 0.1367 - val_accuracy: 0.9474\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9750 - val_loss: 0.1716 - val_accuracy: 0.9181\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9805 - val_loss: 0.1773 - val_accuracy: 0.9240\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9888 - val_loss: 0.1432 - val_accuracy: 0.9415\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9752 - val_loss: 0.1175 - val_accuracy: 0.9415\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9767 - val_loss: 0.1323 - val_accuracy: 0.9415\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9741 - val_loss: 0.2088 - val_accuracy: 0.9064\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.1690 - val_accuracy: 0.9240\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9859 - val_loss: 0.1149 - val_accuracy: 0.9357\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9840 - val_loss: 0.2167 - val_accuracy: 0.9123\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0663 - accuracy: 0.9656 - val_loss: 0.3195 - val_accuracy: 0.8830\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9756 - val_loss: 0.2099 - val_accuracy: 0.9123\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0490 - accuracy: 0.9739 - val_loss: 0.3974 - val_accuracy: 0.8713\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9695 - val_loss: 0.2382 - val_accuracy: 0.9064\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9884 - val_loss: 0.2014 - val_accuracy: 0.9123\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9821 - val_loss: 0.1464 - val_accuracy: 0.9357\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9817 - val_loss: 0.2177 - val_accuracy: 0.9181\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9850 - val_loss: 0.1283 - val_accuracy: 0.9357\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9745 - val_loss: 0.2357 - val_accuracy: 0.9123\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9749 - val_loss: 0.1836 - val_accuracy: 0.9298\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9858 - val_loss: 0.1779 - val_accuracy: 0.9240\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9807 - val_loss: 0.1841 - val_accuracy: 0.9240\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9679 - val_loss: 0.1961 - val_accuracy: 0.9298\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.2269 - val_accuracy: 0.9181\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9765 - val_loss: 0.1734 - val_accuracy: 0.9357\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9836 - val_loss: 0.1908 - val_accuracy: 0.9357\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.1573 - val_accuracy: 0.9357\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9736 - val_loss: 0.1373 - val_accuracy: 0.9240\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9730 - val_loss: 0.1823 - val_accuracy: 0.9357\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9831 - val_loss: 0.1377 - val_accuracy: 0.9240\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9859 - val_loss: 0.1449 - val_accuracy: 0.9357\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9584 - val_loss: 0.1766 - val_accuracy: 0.9357\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9842 - val_loss: 0.2507 - val_accuracy: 0.9181\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9846 - val_loss: 0.2972 - val_accuracy: 0.9181\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9844 - val_loss: 0.3076 - val_accuracy: 0.9240\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9791 - val_loss: 0.3420 - val_accuracy: 0.9064\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9809 - val_loss: 0.1773 - val_accuracy: 0.9298\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.2233 - val_accuracy: 0.9298\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.1730 - val_accuracy: 0.9298\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9907 - val_loss: 0.1719 - val_accuracy: 0.9240\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9877 - val_loss: 0.2151 - val_accuracy: 0.9415\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.3660 - val_accuracy: 0.9181\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.2097 - val_accuracy: 0.9415\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9886 - val_loss: 0.2988 - val_accuracy: 0.9240\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.1860 - val_accuracy: 0.9357\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.9939 - val_loss: 0.2091 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9907 - val_loss: 0.3133 - val_accuracy: 0.9357\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9988 - val_loss: 0.3697 - val_accuracy: 0.9240\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9853 - val_loss: 0.4696 - val_accuracy: 0.9064\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.2570 - val_accuracy: 0.9357\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9794 - val_loss: 0.3371 - val_accuracy: 0.9357\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.2771 - val_accuracy: 0.9357\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.2831 - val_accuracy: 0.9357\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9906 - val_loss: 0.3602 - val_accuracy: 0.9298\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.2624 - val_accuracy: 0.9415\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9906 - val_loss: 0.2361 - val_accuracy: 0.9474\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9907 - val_loss: 0.2253 - val_accuracy: 0.9415\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.4041 - val_accuracy: 0.9240\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9884 - val_loss: 0.2639 - val_accuracy: 0.9415\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9870 - val_loss: 0.2269 - val_accuracy: 0.9298\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9832 - val_loss: 0.3434 - val_accuracy: 0.9298\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.4681 - val_accuracy: 0.9123\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.2485 - val_accuracy: 0.9532\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9873 - val_loss: 0.2663 - val_accuracy: 0.9474\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.2729 - val_accuracy: 0.9415\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.2619 - val_accuracy: 0.9474\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9950 - val_loss: 0.2939 - val_accuracy: 0.9357\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.5208 - val_accuracy: 0.9123\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9929 - val_loss: 0.3515 - val_accuracy: 0.9298\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 0.9918 - val_loss: 0.4324 - val_accuracy: 0.9181\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.2875 - val_accuracy: 0.9357\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 0.3530 - val_accuracy: 0.9298\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9930 - val_loss: 0.2473 - val_accuracy: 0.9357\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.3635 - val_accuracy: 0.9298\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9852 - val_loss: 0.2721 - val_accuracy: 0.9474\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9942 - val_loss: 0.2652 - val_accuracy: 0.9474\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.2206 - val_accuracy: 0.9240\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9926 - val_loss: 0.3181 - val_accuracy: 0.9357\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.3624 - val_accuracy: 0.9298\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.3301 - val_accuracy: 0.9298\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9904 - val_loss: 0.4119 - val_accuracy: 0.9181\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9866 - val_loss: 0.2761 - val_accuracy: 0.9474\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.3496 - val_accuracy: 0.9298\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.3660 - val_accuracy: 0.9298\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.3618 - val_accuracy: 0.9298\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9900 - val_loss: 0.6485 - val_accuracy: 0.9064\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9904 - val_loss: 0.2897 - val_accuracy: 0.9415\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9909 - val_loss: 0.2501 - val_accuracy: 0.9357\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9988 - val_loss: 0.3159 - val_accuracy: 0.9357\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.2581 - val_accuracy: 0.9532\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.2972 - val_accuracy: 0.9415\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9796 - val_loss: 0.2906 - val_accuracy: 0.9415\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.3476 - val_accuracy: 0.9357\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9896 - val_loss: 0.2971 - val_accuracy: 0.9415\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.2497 - val_accuracy: 0.9474\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9915 - val_loss: 0.2743 - val_accuracy: 0.9532\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 0.4904 - val_accuracy: 0.9181\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.3619 - val_accuracy: 0.9298\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.2919 - val_accuracy: 0.9474\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.2374 - val_accuracy: 0.9240\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.2415 - val_accuracy: 0.9415\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.2641 - val_accuracy: 0.9532\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.2866 - val_accuracy: 0.9474\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.4020 - val_accuracy: 0.9181\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.2730 - val_accuracy: 0.9532\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9955 - val_loss: 0.2871 - val_accuracy: 0.9474\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.3170 - val_accuracy: 0.9357\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.2741 - val_accuracy: 0.9532\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9918 - val_loss: 0.2869 - val_accuracy: 0.9474\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.2971 - val_accuracy: 0.9474\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.3378 - val_accuracy: 0.9357\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.3023 - val_accuracy: 0.9474\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.2824 - val_accuracy: 0.9532\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.4486 - val_accuracy: 0.9240\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9897 - val_loss: 0.4318 - val_accuracy: 0.9240\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.2714 - val_accuracy: 0.9532\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.2801 - val_accuracy: 0.9532\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9915 - val_loss: 0.2368 - val_accuracy: 0.9298\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9868 - val_loss: 0.2696 - val_accuracy: 0.9532\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 0.9906 - val_loss: 0.2545 - val_accuracy: 0.9474\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.3144 - val_accuracy: 0.9357\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9885 - val_loss: 0.3528 - val_accuracy: 0.9298\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.2704 - val_accuracy: 0.9532\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4215 - val_accuracy: 0.9123\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.4061 - val_accuracy: 0.9181\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.2708 - val_accuracy: 0.9532\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.3235 - val_accuracy: 0.9357\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.3631 - val_accuracy: 0.9298\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.3084 - val_accuracy: 0.9415\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.3456 - val_accuracy: 0.9415\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.3086 - val_accuracy: 0.9415\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.3777 - val_accuracy: 0.9298\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.3289 - val_accuracy: 0.9474\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9932 - val_loss: 0.4535 - val_accuracy: 0.9123\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.3519 - val_accuracy: 0.9357\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9946 - val_loss: 0.2828 - val_accuracy: 0.9474\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.2975 - val_accuracy: 0.9532\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.2865 - val_accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9787\n",
      "accuracy: 97.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\HARSHA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=1.000, total=   5.4s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.962, total=   4.5s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.981, total=   4.2s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.951, total=   4.5s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   18.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.942, total=   4.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   22.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   8.6s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   31.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.923, total=   8.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   39.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.951, total=   8.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   48.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.971, total=   7.6s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   55.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.922, total=   8.8s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=1.000, total=  13.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.962, total=  24.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.981, total=  14.4s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.932, total=  14.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.942, total=  13.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=1.000, total=   4.2s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.923, total=   3.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.990, total=   4.5s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.942, total=   4.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.893, total=   4.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=1.000, total=   6.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.952, total=   6.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.990, total=   5.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.961, total=   6.2s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.913, total=   5.8s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=1.000, total=   8.5s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.962, total=   8.6s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.981, total=   7.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.942, total=   8.3s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.932, total=   8.7s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=1.000, total=   3.5s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.923, total=   3.7s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.961, total=   3.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x00000215317E0280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.903, total=   4.0s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002153201CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.903, total=   3.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=1.000, total=   5.2s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.962, total=   4.7s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.981, total=   5.0s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.971, total=   6.1s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.932, total=   5.3s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=1.000, total=   9.1s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.942, total=   9.9s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.951, total=   6.4s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.951, total=   8.8s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.913, total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  5.4min finished\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9690067172050476, using {'batch_size': 40, 'epochs': 50}\n",
      "0.9670649647712708,0.020892992307470545 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9535474181175232,0.029547895278249955 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.963181471824646,0.024861122491695094 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.9496639132499695,0.040352387857723764 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9632001519203186,0.030911752182779317 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.963181471824646,0.024861122491695094 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9380134463310241,0.03759139956514438 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9690067172050476,0.022452028728160794 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.951568341255188,0.028100803645324236 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=1.000, total=  10.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.827, total=   7.7s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.524, total=   7.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.883, total=   8.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   33.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.699, total=   7.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   41.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=1.000, total=   7.7s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   48.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.971, total=   8.2s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   57.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.971, total=   8.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.922, total=   7.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.932, total=   7.5s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=1.000, total=   6.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.933, total=   8.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.913, total=   7.2s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.932, total=   8.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.699, total=   7.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=1.000, total=   8.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.750, total=   8.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.524, total=   7.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.680, total=   8.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.699, total=   9.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=1.000, total=   7.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.933, total=   9.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.971, total=  10.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.942, total=   8.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.903, total=   7.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=1.000, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.923, total=  10.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.981, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.932, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.913, total=   8.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=1.000, total=   9.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.750, total=   7.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.524, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.816, total=   8.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.699, total=   8.1s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=1.000, total=   7.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.952, total=   8.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.971, total=   9.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.951, total=   8.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.913, total=   7.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.990, total=   7.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.952, total=   8.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.951, total=   7.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.922, total=   7.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.903, total=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9592793107032775, using {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.7867438435554505,0.16311884737873839 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9592793107032775,0.028428505035275532 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.8952763319015503,0.10250101540227669 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9496452450752259,0.033226395088699526 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9496639370918274,0.03429094063920291 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7577669978141784,0.15494792718215764 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.957374906539917,0.028519286553823717 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9438013434410095,0.029757242453122813 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=1.000, total=   9.4s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.750, total=   7.9s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.476, total=   8.1s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.680, total=   9.0s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   34.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.699, total=   7.8s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   42.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=1.000, total=   7.9s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   50.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.750, total=   8.5s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   58.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.524, total=   8.3s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.320, total=   8.4s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.699, total=   7.6s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=1.000, total=   8.9s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.250, total=   8.0s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.524, total=   8.1s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.680, total=   7.3s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.699, total=   9.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=1.000, total=   8.9s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.760, total=   8.4s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.524, total=   8.5s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.680, total=   9.4s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.699, total=   8.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=1.000, total=   7.6s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.750, total=   9.4s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.767, total=   8.0s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.680, total=   7.8s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.709, total=   8.2s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=1.000, total=   5.8s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.750, total=   4.4s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.524, total=   4.2s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.680, total=   4.4s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.699, total=   5.0s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=1.000, total=   4.2s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.798, total=   4.2s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.728, total=   4.8s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.825, total=   4.4s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.806, total=   3.7s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=1.000, total=   4.0s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.798, total=   3.9s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.670, total=   4.3s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.835, total=   3.8s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.864, total=   4.4s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=1.000, total=   6.8s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.750, total=   8.8s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.524, total=   8.3s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.680, total=   8.3s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.699, total=   9.3s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.981, total=   7.5s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.808, total=   8.2s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.796, total=   7.4s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.893, total=   9.7s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.835, total=   8.2s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=1.000, total=   7.8s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.779, total=   7.8s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.748, total=   8.2s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.883, total=   7.5s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.825, total=   8.2s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=1.000, total=   7.6s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.750, total=   8.5s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.524, total=   8.0s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.680, total=   9.0s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.699, total=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  7.3min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8625466704368592, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.7208737850189209,0.16794994181639633 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.6587378680706024,0.22758449693740784 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.6305825233459472,0.24482772813004766 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7325055956840515,0.15464018573921784 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.781067955493927,0.11368348140357959 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8314600348472595,0.09042987910538497 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8334017992019653,0.10646887045557421 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.8625466704368592,0.06797042833534589 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.8470313668251037,0.08915714180041852 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=1.000, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.750, total=   7.8s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.631, total=   7.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.680, total=   8.8s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   32.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.709, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   40.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=1.000, total=   7.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   48.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.750, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   56.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.670, total=   9.0s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.816, total=   9.2s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.709, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.990, total=   8.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.788, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.631, total=   8.0s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.718, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.748, total=   9.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.990, total=   7.8s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.779, total=   7.8s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.680, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.767, total=   9.6s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.825, total=   8.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=1.000, total=   7.7s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.817, total=   7.7s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.777, total=   9.0s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.864, total=   7.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.806, total=   8.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=1.000, total=   8.0s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.817, total=   8.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.777, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.903, total=   8.2s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.835, total=   8.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=1.000, total=   7.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.827, total=   7.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.748, total=   7.7s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.845, total=   8.3s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.874, total=   7.8s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.981, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.837, total=   8.1s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.816, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.893, total=   8.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.883, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=1.000, total=   8.5s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.875, total=   8.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.932, total=   7.5s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.903, total=   7.6s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.893, total=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9206310629844665, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.7538834810256958,0.1290166798056773 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7888349533081055,0.11607932090301373 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7751867175102234,0.11936377755408464 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.8082150816917419,0.10254418886833715 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8527819275856018,0.07880700107846486 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.866374158859253,0.07826552189242027 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8585885047912598,0.0821576062690045 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8819081306457519,0.05721461628630182 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9206310629844665,0.043767464242193944 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSHA\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845261121856866\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
